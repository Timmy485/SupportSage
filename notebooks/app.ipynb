{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index llama-index-readers-web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.web import FireCrawlWebReader\n",
    "from dotenv import load_dotenv\n",
    "import os, pymongo, pprint\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, ExactMatchFilter, FilterOperator\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FIRECRAWL_API = os.environ.get('FIRECRAWL_API')\n",
    "ATLAS_CONNECTION_STRING = os.environ.get('ATLAS_URI')\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl & Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firecrawl_reader = FireCrawlWebReader(\n",
    "    api_key=FIRECRAWL_API, \n",
    "    mode=\"crawl\",  # Choose between \"crawl\" and \"scrape\" for single page scraping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from a single page URL\n",
    "documents = firecrawl_reader.load_data(url=\"https://truera.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    # Update the 'ogLocaleAlternate' value to None\n",
    "    document.metadata[\"ogLocaleAlternate\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Define the file path\n",
    "file_path = \"documents.pkl\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    # Open the file in binary write mode\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        # Serialize and write the Document object to the file\n",
    "        pickle.dump(documents, f)\n",
    "    print(\"Document saved successfully.\")\n",
    "else:\n",
    "    # Open the file in binary read mode\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        # Load the Document object from the file\n",
    "        documents = pickle.load(f)\n",
    "    print(\"Document loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "# Settings.chunk_size = 100\n",
    "# Settings.chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Instantiate the vector store\n",
    "atlas_vector_search = MongoDBAtlasVectorSearch(\n",
    "    mongodb_client,\n",
    "    db_name = \"truera_db\",\n",
    "    collection_name = \"web_docs\",\n",
    "    index_name = \"truera_vector_index\"\n",
    ")\n",
    " \n",
    "vector_store_context = StorageContext.from_defaults(vector_store=atlas_vector_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_index = VectorStoreIndex.from_documents(\n",
    "   documents, storage_context=vector_store_context, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Atlas Vector Search as a retriever\n",
    "vector_store_retriever = VectorIndexRetriever(index=vector_store_index, similarity_top_k=5)\n",
    "# Pass the retriever into the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=vector_store_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAI(model=\"gpt-4-turbo\")\n",
    "\n",
    "# Connect to your Atlas cluster\n",
    "mongodb_client = pymongo.MongoClient(ATLAS_CONNECTION_STRING)\n",
    "\n",
    "# Instantiate the vector store\n",
    "atlas_vector_search = MongoDBAtlasVectorSearch(\n",
    "    mongodb_client,\n",
    "    db_name = \"truera_db\",\n",
    "    collection_name = \"web_docs\",\n",
    "    index_name = \"truera_vector_index\"\n",
    ")\n",
    "\n",
    "# Create VectorStoreIndex from the vector store\n",
    "vector_store_index = VectorStoreIndex.from_vector_store(atlas_vector_search)\n",
    "\n",
    "# Instantiate Atlas Vector Search as a retriever\n",
    "vector_store_retriever = VectorIndexRetriever(index=vector_store_index, similarity_top_k=5)\n",
    "# Pass the retriever into the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=vector_store_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.query(\"what is truelens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "from trulens_eval.feedback.provider.openai import OpenAI\n",
    "openai = OpenAI()\n",
    "\n",
    "# select context to be used in feedback. the location of context is app specific.\n",
    "from trulens_eval.app import App\n",
    "context = App.select_context(query_engine)\n",
    "\n",
    "# imports for feedback\n",
    "from trulens_eval import Feedback\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "from trulens_eval.feedback import Groundedness\n",
    "grounded = Groundedness(groundedness_provider=OpenAI())\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect()) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(openai.relevance).on_input_output()\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = (\n",
    "    Feedback(openai.qs_relevance)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "tru_query_engine_recorder = TruLlama(query_engine,\n",
    "    app_id='SupportSage_App',\n",
    "    feedbacks=[f_groundedness, f_qa_relevance, f_qs_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What does TruEra do?\",\n",
    "    \"Who uses TruEra?\",\n",
    "    \"How does TruEra interact with my models and data?\",\n",
    "    \"What are the security and privacy policies?\",\n",
    "    \"Can TruEra ingest data from my local files?\",\n",
    "    \"How does Truera help HR organizations\",\n",
    "    \"Why use TruEra for HR?\",\n",
    "    \"Why use TruEra for banking?\",\n",
    "    \"What drives the Truera company?\",\n",
    "    \"What products does truera offer?\",\n",
    "    \"What is truera's culture\",\n",
    "    \"When to use TruLens vs TruEra\"\n",
    "    \"why should i pick TruEra?\",\n",
    "    \"what is TruEra?\",\n",
    "    \"what is TruLens?\",\n",
    "]\n",
    "\n",
    "with tru_query_engine_recorder as recording:\n",
    "    for test in test_queries:\n",
    "        query_engine.query(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The record of the app invocation can be retrieved from the `recording`:\n",
    "\n",
    "# rec = recording.get() # use .get if only one record\n",
    "recs = recording.records # use .records if multiple\n",
    "\n",
    "display(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[\"SupportSage_App\"])\n",
    "\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[\"SupportSage_App\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
